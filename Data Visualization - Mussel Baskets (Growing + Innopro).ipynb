{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe3fa9b",
   "metadata": {},
   "source": [
    "# Data Visualization - Mussel Baskets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325540e9",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fd41f",
   "metadata": {},
   "source": [
    "#### Function Descriptions and Usage\n",
    "\n",
    "##### `verify_access_code`\n",
    "- **Purpose**: Verifies the access code provided by the user.\n",
    "- **Usage**: Hashes the input code using SHA256 and compares it to a pre-defined hashed access code. This ensures only users with the correct access code can proceed to use the application.\n",
    "\n",
    "##### `load_trained_model`\n",
    "- **Purpose**: Loads a trained machine learning model from a file.\n",
    "- **Usage**: Uses Joblib to load the model necessary for making growth predictions.\n",
    "\n",
    "##### `load_data`\n",
    "- **Purpose**: Loads data from a CSV file into a Pandas DataFrame.\n",
    "- **Usage**: Reads various datasets needed for the application.\n",
    "\n",
    "##### `create_sidebar`\n",
    "- **Purpose**: Creates a sidebar for user settings in the Streamlit app.\n",
    "- **Usage**: Allows selection of year range and locations. The selections are returned as a tuple to filter the data displayed on the dashboard.\n",
    "\n",
    "##### `display_main_map`\n",
    "- **Purpose**: Displays an interactive map with mussel growth data.\n",
    "- **Usage**: Uses Plotly Express to show bubbles representing mussel growth, colored by a selected feature and animated by month. Filters data based on user-selected years and locations.\n",
    "\n",
    "##### `display_graphs`\n",
    "- **Purpose**: Displays interactive graphs for various metrics over time.\n",
    "- **Usage**: Uses Plotly Graph Objects to plot data based on user-selected years and locations, providing visual insights into mussel growth trends.\n",
    "\n",
    "##### `display_feature_vs_target_analysis`\n",
    "- **Purpose**: Compares a selected feature against Growth (g per day).\n",
    "- **Usage**: Creates an interactive graph using user-selected years and locations to filter and plot the data for detailed feature analysis.\n",
    "\n",
    "##### `haversine`\n",
    "- **Purpose**: Calculates the great-circle distance between two points on the Earth's surface.\n",
    "- **Usage**: Given latitude and longitude, computes the distance, useful for finding the nearest environmental data point.\n",
    "\n",
    "##### `get_nearest_environmental_data`\n",
    "- **Purpose**: Finds the nearest environmental data point for a specific month.\n",
    "- **Usage**: Filters data by month and calculates distances using the haversine function to return the closest data point, providing accurate environmental data inputs for growth predictions.\n",
    "\n",
    "##### `calculate_average_ash_free_dry_weight`\n",
    "- **Purpose**: Calculates the average Ash Free Dry Weight (g) for a specified monitoring period.\n",
    "- **Usage**: Filters relevant data and computes the mean to provide necessary input for the growth prediction model.\n",
    "\n",
    "##### `predict_growth`\n",
    "- **Purpose**: Predicts mussel growth based on user inputs and additional environmental features.\n",
    "- **Usage**: Uses the trained model to make predictions for each monitoring period from May to October and returns the results in a DataFrame.\n",
    "\n",
    "##### `display_prediction_interface`\n",
    "- **Purpose**: Creates the interface for mussel growth prediction.\n",
    "- **Usage**: Allows users to input latitude, longitude, and individual weight, then predicts growth based on these inputs. Displays the predictions and a corresponding plot.\n",
    "\n",
    "##### `display_data`\n",
    "- **Purpose**: Displays the interactive map, graphs, and prediction interface in the Streamlit app.\n",
    "- **Usage**: Uses sidebar selections to filter data and calls relevant display functions to show visualizations and predictions.\n",
    "\n",
    "##### `main`\n",
    "- **Purpose**: Runs the Streamlit app for the Mussel Growth Trends Dashboard.\n",
    "- **Usage**: Handles access control, loads necessary data and model files upon successful access verification, and calls the `display_data` function to render the dashboard.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This Streamlit application visualizes mussel growth data through interactive maps and graphs, and allows users to predict growth based on various environmental factors. The `verify_access_code` function secures access to the app, while `load_trained_model` and `load_data` handle loading necessary files. The sidebar for user input is created by `create_sidebar`. The core display functions `display_main_map`, `display_graphs`, and `display_feature_vs_target_analysis` render the main visual elements based on user inputs. Environmental data is managed through `get_nearest_environmental_data` and `calculate_average_ash_free_dry_weight`, with distance calculations done by `haversine`. Growth predictions are facilitated by `predict_growth` and its interface is managed by `display_prediction_interface`. The `display_data` function integrates these components into the main app, which is initialized and run by the `main` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d08f99e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mussel_visualization.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mussel_visualization.py\n",
    "\n",
    "# Streamlit for creating the web application interface\n",
    "import streamlit as st\n",
    "\n",
    "# Pandas for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Folium and streamlit_folium for interactive maps\n",
    "import folium\n",
    "from streamlit_folium import folium_static, st_folium\n",
    "\n",
    "# NumPy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Plotly for creating interactive plots and charts\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Matplotlib for additional plotting utilities\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# Joblib for model serialization\n",
    "import joblib\n",
    "\n",
    "# Hashlib for hashing access codes\n",
    "import hashlib\n",
    "\n",
    "# Math functions for distance calculations\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# OS for file operations (not used, can be removed if not needed)\n",
    "import os\n",
    "\n",
    "\n",
    "access_granted = False\n",
    "\n",
    "st.set_page_config(layout=\"wide\", page_title=\"Mussel Growth Trends Dashboard\", page_icon=\"üêö\")\n",
    "\n",
    "def verify_access_code(input_code):\n",
    "    \"\"\"\n",
    "    Verifies the access code provided by the user.\n",
    "\n",
    "    This function hashes the input code using SHA256 and compares it to a pre-defined \n",
    "    hashed access code. It is used to ensure that only users with the correct access \n",
    "    code can proceed to use the application.\n",
    "\n",
    "    Args:\n",
    "        input_code (str): The access code input by the user.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the input code matches the pre-defined hashed access code, False otherwise.\n",
    "    \"\"\"\n",
    "    # Hash the input code using SHA256\n",
    "    hashed_input = hashlib.sha256(input_code.encode()).hexdigest()\n",
    "\n",
    "    # Pre-defined hashed version of the correct access code\n",
    "    # Note: To generate this hash for a new access code, use the following code snippet in a separate cell:\n",
    "    # import hashlib\n",
    "    # correct_code = 'your_desired_access_code'\n",
    "    # print(hashlib.sha256(correct_code.encode()).hexdigest())\n",
    "    hashed_access_code = 'd0601b8185961d8e3e0ea3bbbeca893e630abfa2f9617a5122a431f498bcfe6e'\n",
    "\n",
    "    # Compare the hashed input code with the pre-defined hashed access code\n",
    "    return hashed_input == hashed_access_code\n",
    "\n",
    "def load_trained_model(file_path):\n",
    "    \"\"\"\n",
    "    Loads the trained model from a file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the model file.\n",
    "\n",
    "    Returns:\n",
    "        model: The loaded model.\n",
    "    \"\"\"\n",
    "    return joblib.load(file_path)\n",
    "\n",
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    Loads the data from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "def create_sidebar(df):\n",
    "    \"\"\"\n",
    "    Creates a sidebar in the Streamlit app for user settings, allowing selection of years and locations.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the selected year range and location selection.\n",
    "    \"\"\"\n",
    "    # Set the title and header for the sidebar\n",
    "    st.sidebar.title(\"Settings\")\n",
    "    \n",
    "    # Add spacing\n",
    "    st.sidebar.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Multiselect widget for selecting year(s)\n",
    "    year_range = st.sidebar.multiselect(\n",
    "        'üìÖ Select Year(s)',\n",
    "        options=list(range(int(df['Year'].min()), int(df['Year'].max()) + 1)), \n",
    "        default=list(range(int(df['Year'].min()), int(df['Year'].max()) + 1))\n",
    "    )\n",
    "    \n",
    "    # Instruction for year selection\n",
    "    st.sidebar.markdown(\"\"\"\n",
    "    <div style=\"border: 1px solid #ccc; padding: 10px; border-radius: 5px; font-size: 12px; margin-top: -10px;\">\n",
    "    <b>Note</b>: Selecting more than one year will average the values for all selected years.\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Add spacing\n",
    "    st.sidebar.markdown(\"<br>\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Prepare location options by combining 'System' and 'Plot Location'\n",
    "    location_options = df[['System', 'Plot Location']].drop_duplicates()\n",
    "    location_options['Location_System'] = location_options['System'] + ' - ' + location_options['Plot Location']\n",
    "    \n",
    "    # Multiselect widget for selecting locations\n",
    "    location_selection = st.sidebar.multiselect(\n",
    "        'üìç Select Locations',\n",
    "        options=location_options['Location_System'].sort_values()\n",
    "    )\n",
    "    \n",
    "    # Instruction for location selection\n",
    "    st.sidebar.markdown(\"\"\"\n",
    "    <div style=\"border: 1px solid #ccc; padding: 10px; border-radius: 5px; font-size: 12px; margin-top: -10px;\">\n",
    "    <b>Note</b>: If no location is selected, the data will be averaged per system.\n",
    "    Selecting more than one location will display data per location.\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Return the selected year range and location selection\n",
    "    return year_range, location_selection\n",
    "\n",
    "def display_main_map(df, year_range, location_selection):\n",
    "    \"\"\"\n",
    "    Displays an interactive map with bubbles representing mussel growth data, colored by a selected feature and animated by month.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        year_range (list): List of selected years.\n",
    "        location_selection (list): List of selected locations.\n",
    "    \"\"\"\n",
    "    # User selection for the feature to color the map bubbles\n",
    "    selected_color_feature = st.selectbox('Select feature for bubble color', [\n",
    "        'Precipitation', 'Sea Surface Temperature (C)', 'Chlorophyll (mg per m3)', 'Turbidity (FTU)'\n",
    "    ], help=\"The color scale represents the selected feature, indicating its intensity.\")\n",
    "    \n",
    "    # Add a custom information box\n",
    "    st.markdown(\"\"\"\n",
    "        <div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; color: #856404; font-size: 16px; margin-bottom: 20px;\">\n",
    "            <strong>Note</strong>: Color scale indicates the intensity of the selected feature, and bubble size represents the magnitude of growth (g per day).\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Filter the dataframe based on the selected years\n",
    "    df_filtered = df[df['Year'].isin(year_range)]\n",
    "\n",
    "    # If specific locations are selected, filter the dataframe accordingly\n",
    "    if location_selection:\n",
    "        df_filtered['Location_System'] = df_filtered['System'] + ' - ' + df_filtered['Plot Location']\n",
    "        df_filtered = df_filtered[df_filtered['Location_System'].isin(location_selection)]\n",
    "\n",
    "    # Exclude data for Monitoring Period 0\n",
    "    df_filtered = df_filtered[df_filtered['Monitoring Period'] > 0]\n",
    "\n",
    "    # Group the filtered data by specific columns and calculate the mean for each group\n",
    "    df_grouped = df_filtered.groupby([\n",
    "        'lat', 'lon', 'Plot Location', 'System', 'Month', 'Monitoring Period'\n",
    "    ]).mean().round(2).reset_index()\n",
    "\n",
    "    # Rename columns for better readability in the hover information\n",
    "    df_grouped.rename(columns={'lat': 'Latitude', 'lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "    # Sort the grouped data by Monitoring Period\n",
    "    df_grouped.sort_values(by='Monitoring Period', inplace=True)\n",
    "\n",
    "    # Create the scatter mapbox figure using Plotly Express\n",
    "    fig = px.scatter_mapbox(\n",
    "        df_grouped,\n",
    "        lat=\"Latitude\",\n",
    "        lon=\"Longitude\",\n",
    "        color=selected_color_feature,\n",
    "        size=\"Growth (g per day)\",\n",
    "        size_max=25,\n",
    "        hover_name=\"Plot Location\",\n",
    "        hover_data={\n",
    "            \"System\": True,\n",
    "            \"Latitude\": False,\n",
    "            \"Longitude\": False,\n",
    "            selected_color_feature: True,\n",
    "            \"Growth (g per day)\": True,\n",
    "            \"Month\": True\n",
    "        },\n",
    "        animation_frame=\"Monitoring Period\",\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        color_continuous_scale=px.colors.sequential.Viridis,\n",
    "        zoom=7,\n",
    "        center={\"lat\": df['lat'].mean(), \"lon\": df['lon'].mean()}\n",
    "    )\n",
    "\n",
    "    # Update the layout of the figure\n",
    "    fig.update_layout(\n",
    "        margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "        mapbox=dict(bearing=0, pitch=0),\n",
    "        coloraxis_colorbar=dict(title=selected_color_feature),\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    # Display the figure using Streamlit\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "def display_graphs(df, year_range, location_selection):\n",
    "    \"\"\"\n",
    "    Displays interactive graphs showing various metrics over time.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        year_range (list): List of selected years.\n",
    "        location_selection (list): List of selected locations.\n",
    "    \"\"\"\n",
    "    st.header(\"üìà Graphs\")  # Add a header for the graphs section\n",
    "    \n",
    "    # Define the metrics to be plotted, ordered by importance\n",
    "    metrics = ['Growth (g per day)', 'Chlorophyll (mg per m3)', 'Sea Surface Temperature (C)', \n",
    "               'Turbidity (FTU)', 'Precipitation', 'Individual Weight (g)', \n",
    "               'Depth (m)', 'Average Flow Speed (mps)', 'Maximum Flow Speed (mps)', 'Living Mussel Count']\n",
    "\n",
    "    # Create two columns for displaying the plots\n",
    "    col1, col2 = st.columns(2)\n",
    "    \n",
    "    # Define colors for different systems\n",
    "    system_colors = {'OS': 'orange', 'WAD': 'green'}\n",
    "    \n",
    "    # Create a colormap for location colors\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    location_colors = [mcolors.to_hex(cmap(i)) for i in np.linspace(0, 1, len(location_selection))]\n",
    "\n",
    "    # Filter the dataframe based on the selected years\n",
    "    df_filtered = df[df['Year'].isin(year_range)]\n",
    "\n",
    "    # Initialize a counter to alternate between columns\n",
    "    counter = 0\n",
    "\n",
    "    # Loop through each metric to create a plot\n",
    "    for metric in metrics:\n",
    "        fig = go.Figure()  # Create a new figure for each metric\n",
    "        added_systems = set()  # Track systems that have been added to the plot\n",
    "\n",
    "        # If specific locations are selected, plot each location's data\n",
    "        if location_selection:\n",
    "            # Create a dictionary to map locations to colors\n",
    "            location_colors_dict = {location: color for location, color in zip(location_selection, location_colors)}\n",
    "            \n",
    "            # Loop through each selected location\n",
    "            for location in location_selection:\n",
    "                if ' - ' in location:\n",
    "                    # Split the location string into system and plot location\n",
    "                    system, plot_location = location.split(' - ', 1)\n",
    "                    \n",
    "                    # Filter the data for the specific system and plot location\n",
    "                    df_location = df_filtered[(df_filtered['System'] == system) & \n",
    "                                              (df_filtered['Plot Location'] == plot_location)].dropna()\n",
    "                    \n",
    "                    # Group by 'Month' and 'Monitoring Period', and calculate the mean for the metric\n",
    "                    df_location_avg = df_location.groupby(['Month', 'Monitoring Period'])[metric].mean().reset_index()\n",
    "                    \n",
    "                    # Sort the grouped data by 'Monitoring Period'\n",
    "                    df_location_avg.sort_values(by='Monitoring Period', inplace=True)\n",
    "\n",
    "                    # Add a trace for the location's data\n",
    "                    fig.add_trace(go.Scatter(x=df_location_avg['Month'], y=df_location_avg[metric], \n",
    "                                             mode='lines+markers', \n",
    "                                             name=f'Average at {plot_location}', \n",
    "                                             line=dict(shape='spline', color=location_colors_dict[location]),\n",
    "                                             marker=dict(symbol='circle')))\n",
    "                    \n",
    "                    # Add system average line if not already added\n",
    "                    if system not in added_systems:\n",
    "                        df_system_avg = df_filtered[df_filtered['System'] == system].groupby(['Month', 'Monitoring Period'])[metric].mean().reset_index()\n",
    "                        df_system_avg.sort_values(by='Monitoring Period', inplace=True)\n",
    "                        fig.add_trace(go.Scatter(x=df_system_avg['Month'], y=df_system_avg[metric], \n",
    "                                                 mode='lines+markers', \n",
    "                                                 line=dict(dash='dash', shape='spline', color=system_colors[system]), \n",
    "                                                 name=f'Average in {system} System',\n",
    "                                                 marker=dict(symbol='circle')))\n",
    "                        added_systems.add(system)\n",
    "                else:\n",
    "                    st.warning(f\"Invalid location format: {location}\")\n",
    "        else:\n",
    "            # If no specific locations are selected, plot each system's average data\n",
    "            for system in df['System'].unique():\n",
    "                df_system_avg = df_filtered[df_filtered['System'] == system].groupby(['Month', 'Monitoring Period'])[metric].mean().reset_index()\n",
    "                df_system_avg.sort_values(by='Monitoring Period', inplace=True)\n",
    "                fig.add_trace(go.Scatter(x=df_system_avg['Month'], y=df_system_avg[metric], \n",
    "                                         mode='lines+markers', \n",
    "                                         name=f'Average {system}', \n",
    "                                         line=dict(shape='spline', color=system_colors[system]),\n",
    "                                         marker=dict(symbol='circle')))\n",
    "\n",
    "        # Update the layout of the figure\n",
    "        fig.update_layout(template=\"plotly_dark\", title=f\"{metric} Trends - {', '.join(map(str, year_range))}\")\n",
    "        \n",
    "        # Alternate between the two columns for displaying the charts\n",
    "        with (col1 if counter % 2 == 0 else col2):\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "        counter += 1  # Increment the counter to alternate columns\n",
    "            \n",
    "def display_feature_vs_target_analysis(df, year_range, location_selection):\n",
    "    \"\"\"\n",
    "    Displays an interactive graph comparing a selected feature against Growth (g per day).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        year_range (list): List of selected years.\n",
    "        location_selection (list): List of selected locations.\n",
    "    \"\"\"\n",
    "    st.header(\"üîç Growth (g per day) Feature Analysis\")  # Header for the analysis section\n",
    "    \n",
    "    # Define the available metrics\n",
    "    metrics = ['Growth (g per day)', 'Chlorophyll (mg per m3)', 'Sea Surface Temperature (C)', \n",
    "               'Turbidity (FTU)', 'Precipitation', 'Individual Weight (g)', \n",
    "               'Depth (m)', 'Average Flow Speed (mps)', 'Maximum Flow Speed (mps)', 'Living Mussel Count']\n",
    "    \n",
    "    # Create a list of feature options excluding 'Growth (g per day)'\n",
    "    feature_options = [metric for metric in metrics if metric != 'Growth (g per day)']\n",
    "    \n",
    "    # Selectbox for the user to choose a feature to plot against 'Growth (g per day)'\n",
    "    selected_feature = st.selectbox('Select a feature to plot against Growth (g per day)', options=feature_options)\n",
    "\n",
    "    if selected_feature:\n",
    "        # Filter the dataframe based on the selected years\n",
    "        df_filtered = df[df['Year'].isin(year_range)]\n",
    "        \n",
    "        # If specific locations are selected, filter based on those locations\n",
    "        if location_selection:\n",
    "            df_filtered['Location_System'] = df_filtered['System'] + ' - ' + df_filtered['Plot Location']\n",
    "            df_filtered = df_filtered[df_filtered['Location_System'].isin(location_selection)]\n",
    "        \n",
    "        # Create a new figure for plotting\n",
    "        fig = go.Figure()\n",
    "\n",
    "        if location_selection:\n",
    "            # Loop through each selected location\n",
    "            for location in location_selection:\n",
    "                if ' - ' in location:\n",
    "                    # Split the location string into system and plot location\n",
    "                    system, plot_location = location.split(' - ', 1)\n",
    "                    \n",
    "                    # Filter the data for the specific system and plot location\n",
    "                    df_location = df_filtered[(df_filtered['System'] == system) & \n",
    "                                              (df_filtered['Plot Location'] == plot_location)].dropna()\n",
    "                    \n",
    "                    # Group by 'Month' and 'Monitoring Period', and calculate the mean for the selected feature and target\n",
    "                    df_grouped = df_location.groupby(['Month', 'Monitoring Period']).mean().reset_index()\n",
    "                    \n",
    "                    # Sort the grouped data by 'Monitoring Period'\n",
    "                    df_grouped.sort_values(by='Monitoring Period', inplace=True)\n",
    "\n",
    "                    # Add a trace for the selected feature\n",
    "                    fig.add_trace(go.Scatter(x=df_grouped['Month'], y=df_grouped[selected_feature], mode='lines+markers', \n",
    "                                             name=f'{selected_feature} at {plot_location}', yaxis='y1', line_shape='spline'))\n",
    "                    \n",
    "                    # Add a trace for 'Growth (g per day)'\n",
    "                    fig.add_trace(go.Scatter(x=df_grouped['Month'], y=df_grouped['Growth (g per day)'], mode='lines+markers', \n",
    "                                             name=f'Growth (g per day) at {plot_location}', line=dict(width=4, dash='dash'), yaxis='y2', line_shape='spline'))\n",
    "        else:\n",
    "            # If no specific locations are selected, plot the data for each system\n",
    "            for system in df['System'].unique():\n",
    "                df_system = df_filtered[df_filtered['System'] == system].dropna()\n",
    "                \n",
    "                # Group by 'Month' and 'Monitoring Period', and calculate the mean for the selected feature and target\n",
    "                df_grouped = df_system.groupby(['Month', 'Monitoring Period']).mean().reset_index()\n",
    "                \n",
    "                # Sort the grouped data by 'Monitoring Period'\n",
    "                df_grouped.sort_values(by='Monitoring Period', inplace=True)\n",
    "\n",
    "                # Add a trace for the selected feature\n",
    "                fig.add_trace(go.Scatter(x=df_grouped['Month'], y=df_grouped[selected_feature], mode='lines+markers', \n",
    "                                         name=f'{selected_feature} in {system} System', yaxis='y1', line_shape='spline'))\n",
    "                \n",
    "                # Add a trace for 'Growth (g per day)'\n",
    "                fig.add_trace(go.Scatter(x=df_grouped['Month'], y=df_grouped['Growth (g per day)'], mode='lines+markers', \n",
    "                                         name=f'Growth (g per day) in {system} System', line=dict(width=4, dash='dash'), yaxis='y2', line_shape='spline'))\n",
    "\n",
    "        # Update the layout of the figure\n",
    "        fig.update_layout(\n",
    "            title=f\"{selected_feature} vs Growth (g per day)\",\n",
    "            xaxis_title='Month',\n",
    "            yaxis=dict(title=f'{selected_feature} Values', side='left'),\n",
    "            yaxis2=dict(title='Growth (g per day)', overlaying='y', side='right'),\n",
    "            height=600,\n",
    "            template=\"plotly_dark\"\n",
    "        )\n",
    "\n",
    "        # Display the figure\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "        \n",
    "def display_location_rankings(df):\n",
    "    \"\"\"\n",
    "    Displays a ranking table of locations based on the average of selected metrics over all years.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    # Select the metrics to rank locations\n",
    "    metrics = ['Growth (g per day)', 'Precipitation', 'Sea Surface Temperature (C)', 'Chlorophyll (mg per m3)', 'Turbidity (FTU)']\n",
    "    \n",
    "    # Calculate the average of each metric for each location and system\n",
    "    df_rankings = df.groupby(['Plot Location', 'System'])[metrics].mean().round(2).reset_index()\n",
    "    \n",
    "    # Sort by 'Growth (g per day)' in descending order\n",
    "    df_rankings = df_rankings.sort_values(by='Growth (g per day)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Display the rankings table with a header\n",
    "    st.header(\"üìä Location Rankings Based on Average Metrics\")\n",
    "    \n",
    "    # Add a custom information box\n",
    "    st.markdown(\"\"\"\n",
    "        <div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; color: #856404; font-size: 16px; margin-bottom: 20px;\">\n",
    "            <strong>Note</strong>: The table below shows the ranking of locations based on the average of selected metrics over all years.\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "    \n",
    "    # Display the dataframe as a table\n",
    "    st.dataframe(df_rankings, use_container_width=True)\n",
    "\n",
    "def haversine(latitude1, longitude1, latitude2, longitude2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points \n",
    "    on the Earth's surface given their latitude and longitude.\n",
    "    \n",
    "    Parameters:\n",
    "    - latitude1: Latitude of the first point in decimal degrees.\n",
    "    - longitude1: Longitude of the first point in decimal degrees.\n",
    "    - latitude2: Latitude of the second point in decimal degrees.\n",
    "    - longitude2: Longitude of the second point in decimal degrees.\n",
    "    \n",
    "    Returns:\n",
    "    - distance: The distance between the two points in kilometers.\n",
    "    \"\"\"\n",
    "    # Radius of the Earth in kilometers\n",
    "    earth_radius_km = 6371.0\n",
    "\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    delta_latitude = radians(latitude2 - latitude1)\n",
    "    delta_longitude = radians(longitude2 - longitude1)\n",
    "    \n",
    "    # Apply the Haversine formula to calculate the great-circle distance\n",
    "    a = sin(delta_latitude / 2)**2 + cos(radians(latitude1)) * cos(radians(latitude2)) * sin(delta_longitude / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    # Calculate the distance\n",
    "    distance = earth_radius_km * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "def get_nearest_environmental_data(latitude, longitude, dataframe, month):\n",
    "    \"\"\"\n",
    "    Find the nearest environmental data point to a given latitude and longitude for a specific month.\n",
    "\n",
    "    Parameters:\n",
    "    - latitude: Latitude of the target location in decimal degrees.\n",
    "    - longitude: Longitude of the target location in decimal degrees.\n",
    "    - dataframe: DataFrame containing the environmental data with 'lat' and 'lon' columns.\n",
    "    - month: The month for which to filter the data.\n",
    "\n",
    "    Returns:\n",
    "    - nearest_row: The row from the DataFrame that is closest to the given location for the specified month.\n",
    "    \"\"\"\n",
    "    global df_environment  # Add this line\n",
    "    \n",
    "    # Filter the dataframe for the specified month\n",
    "    monthly_data = dataframe[dataframe['month'] == month].copy()\n",
    "\n",
    "    # Calculate the distance from the target location for each row in the filtered dataframe\n",
    "    monthly_data['distance'] = monthly_data.apply(\n",
    "        lambda row: haversine(latitude, longitude, row['lat'], row['lon']), axis=1\n",
    "    )\n",
    "\n",
    "    # Find the row with the minimum distance\n",
    "    nearest_row = monthly_data.loc[monthly_data['distance'].idxmin()]\n",
    "    \n",
    "    return nearest_row\n",
    "\n",
    "def calculate_average_ash_free_dry_weight(monitoring_period):\n",
    "    \"\"\"\n",
    "    Calculate the average Ash Free Dry Weight (g) for the specified monitoring period.\n",
    "\n",
    "    Parameters:\n",
    "    - monitoring_period: The monitoring period for which to calculate the average weight.\n",
    "\n",
    "    Returns:\n",
    "    - average_weight: The average Ash Free Dry Weight (g) for the specified period.\n",
    "    \"\"\"\n",
    "    # Filter the dataframe for the specified monitoring period\n",
    "    period_data = df_modeling[df_modeling['Monitoring Period'] == monitoring_period]\n",
    "    \n",
    "    # Calculate the mean of 'Ash Free Dry Weight (g)_lag' for the filtered data\n",
    "    average_weight = period_data['Ash Free Dry Weight (g)_lag'].mean()\n",
    "    \n",
    "    return average_weight\n",
    "\n",
    "def predict_growth(latitude, longitude, initial_weight):\n",
    "    \"\"\"\n",
    "    Predict mussel growth based on user inputs and additional environmental features.\n",
    "\n",
    "    Parameters:\n",
    "    - latitude: Latitude of the location.\n",
    "    - longitude: Longitude of the location.\n",
    "    - initial_weight: Initial weight of the mussel.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: DataFrame with columns 'Month' and 'Growth (g per day)'.\n",
    "    \"\"\"\n",
    "    # Get nearest environmental data for April (lag) and May (current)\n",
    "    env_data_april = get_nearest_environmental_data(latitude, longitude, df_environment, 4)\n",
    "    env_data_may = get_nearest_environmental_data(latitude, longitude, df_environment, 5)\n",
    "\n",
    "    # Create input data dictionary for prediction\n",
    "    input_data = {\n",
    "        'Chlorophyll': [env_data_may.get('chlorophyll', 0)],\n",
    "        'Water Temperature (C)': [env_data_may.get('sst', 0)],\n",
    "        'Water Temperature (C)_lag': [env_data_april.get('sst', 0)],\n",
    "        'Ash Free Dry Weight (g)_lag': [calculate_average_ash_free_dry_weight(0)],\n",
    "        'Number of Days': [30],\n",
    "        'Precipitation_lag': [env_data_april.get('precipitation', 0)],\n",
    "        'Turbidity (FTU)': [env_data_may.get('turbidity', 0)],\n",
    "        'Turbidity (FTU)_lag': [env_data_april.get('turbidity', 0)],\n",
    "        'Monitoring Period': [0],\n",
    "        'Individual Weight (g)_lag': [initial_weight],\n",
    "        'Chlorophyll_lag': [env_data_april.get('chlorophyll', 0)]\n",
    "    }\n",
    "\n",
    "    # Convert input data dictionary to DataFrame\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    predictions = []\n",
    "\n",
    "    # Perform predictions for each monitoring period from May to October\n",
    "    for period in range(1, 7):\n",
    "        # Predict growth using the loaded model\n",
    "        prediction = loaded_model.predict(input_df[[\n",
    "            'Chlorophyll', 'Water Temperature (C)', 'Water Temperature (C)_lag', \n",
    "            'Ash Free Dry Weight (g)_lag', 'Number of Days', 'Precipitation_lag', \n",
    "            'Turbidity (FTU)', 'Turbidity (FTU)_lag', 'Monitoring Period', \n",
    "            'Individual Weight (g)_lag', 'Chlorophyll_lag']])[0]\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Update input data for the next period\n",
    "        input_df['Monitoring Period'] = period\n",
    "        input_df['Growth (g per day)'] = prediction\n",
    "        input_df['Ash Free Dry Weight (g)_lag'] = calculate_average_ash_free_dry_weight(period)\n",
    "\n",
    "    # Create a DataFrame for predictions with 'Month' and 'Growth (g per day)'\n",
    "    months = ['May', 'June', 'July', 'August', 'September', 'October']\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'Month': months,\n",
    "        'Growth (g per day)': predictions\n",
    "    })\n",
    "\n",
    "    return prediction_df\n",
    "\n",
    "def display_prediction_interface():\n",
    "    \"\"\"\n",
    "    Displays the prediction interface for mussel growth. Allows users to input latitude, longitude, \n",
    "    and individual weight, then predicts growth based on these inputs.\n",
    "    \"\"\"\n",
    "    st.header(\"üîÆ Predict Mussel Growth\")\n",
    "\n",
    "    # Custom warning box for model disclaimer\n",
    "    st.markdown(\"\"\"\n",
    "        <div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px; color: #856404; font-size: 16px; margin-bottom: 20px;\">\n",
    "            <strong>Disclaimer</strong>: The predictions provided here are based on a trained model. \n",
    "            While the model has been developed and tested with historical data, \n",
    "            the predictions are not guaranteed to be 100% accurate. \n",
    "            Please use these predictions as a guideline and not as a definitive forecast.\n",
    "        </div>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Initial coordinates for Amsterdam\n",
    "    initial_lat = 52.3676\n",
    "    initial_lon = 4.9041\n",
    "\n",
    "    # User inputs for prediction\n",
    "    lat = st.number_input('Latitude', value=initial_lat, format=\"%.6f\")\n",
    "    lon = st.number_input('Longitude', value=initial_lon, format=\"%.6f\")\n",
    "    individual_weight = st.number_input('Individual Weight (g)', value=2.0, min_value=0.1)\n",
    "\n",
    "    # Button click state initialization\n",
    "    if 'predict_clicked' not in st.session_state:\n",
    "        st.session_state['predict_clicked'] = False\n",
    "\n",
    "    button_placeholder = st.empty()  # Placeholder for the predict button\n",
    "\n",
    "    # Display the predict button if prediction has not been clicked yet\n",
    "    if not st.session_state['predict_clicked']:\n",
    "        if button_placeholder.button(\"Predict Growth\", key=\"predict\"):\n",
    "            st.session_state['predict_clicked'] = True  # Update state to indicate button was clicked\n",
    "            with st.spinner('Predicting...'):\n",
    "                # Perform prediction\n",
    "                predictions_df = predict_growth(lat, lon, individual_weight)\n",
    "                st.session_state['predictions'] = predictions_df  # Store predictions in session state\n",
    "\n",
    "    # Display predictions and plot if available\n",
    "    if st.session_state['predict_clicked'] and 'predictions' in st.session_state:\n",
    "        st.write(st.session_state['predictions'])  # Display predictions DataFrame\n",
    "\n",
    "        # Create a plot of the predictions\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=st.session_state['predictions']['Month'], \n",
    "            y=st.session_state['predictions']['Growth (g per day)'], \n",
    "            mode='lines+markers', \n",
    "            line_shape='spline'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=\"Predicted Growth (g per day) for Each Month\", \n",
    "            xaxis_title=\"Month\", \n",
    "            yaxis_title=\"Growth (g per day)\"\n",
    "        )\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "        # Reset the state for the next prediction\n",
    "        st.session_state['predict_clicked'] = False\n",
    "        st.session_state.pop('predictions', None)\n",
    "        button_placeholder.button(\"Predict Growth\", key=\"predict_new\")\n",
    "        \n",
    "def display_data(df):\n",
    "    \"\"\"\n",
    "    Main function to display the interactive map, graphs, and prediction interface in the Streamlit app.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the sidebar and get the user's selections\n",
    "    year_range, location_selection = create_sidebar(df)\n",
    "\n",
    "    # Apply custom styling using CSS for font family\n",
    "    st.markdown(\"\"\"\n",
    "    <style>\n",
    "    @import url('https://fonts.googleapis.com/css2?family=Inter&display=swap');\n",
    "    h1, h2, h3, h4, h5, h6, p {\n",
    "        font-family: 'Inter', sans-serif;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "    # Markdown block to provide an overview and instructions for the app\n",
    "    st.markdown(\"\"\"\n",
    "    > This dashboard visualizes mussel growth data from various locations in the Netherlands. \n",
    "    > Use the sidebar to filter data by year and location.\n",
    "    > The map shows mussel baskets with different colors representing different systems. \n",
    "    > Charts below display detailed growth trends. Hover over them for more information.\n",
    "    \"\"\")\n",
    "\n",
    "    # Display header for the map section\n",
    "    st.header(\"üåç Map\")\n",
    "\n",
    "    # Display the main interactive map\n",
    "    display_main_map(df, year_range, location_selection)\n",
    "    \n",
    "    # Add a divider for better visual separation\n",
    "    st.divider()\n",
    "\n",
    "    # Display graphs for various metrics over time\n",
    "    display_graphs(df, year_range, location_selection)\n",
    "\n",
    "    # Add another divider\n",
    "    st.divider()\n",
    "\n",
    "    # Display analysis comparing selected features against Growth (g per day)\n",
    "    display_feature_vs_target_analysis(df, year_range, location_selection)\n",
    "    \n",
    "    # Add another divider\n",
    "    st.divider()\n",
    "\n",
    "    # Display location rankings\n",
    "    display_location_rankings(df)\n",
    "    \n",
    "    # Add a final divider\n",
    "    st.divider()\n",
    "    \n",
    "    # Display the prediction interface for predicting mussel growth\n",
    "    display_prediction_interface()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the Streamlit app for Mussel Growth Trends Dashboard.\n",
    "    \"\"\"\n",
    "    # Set the title of the Streamlit app\n",
    "    st.title('ü¶™ Mussel Growth Trends Dashboard'.upper())\n",
    "\n",
    "    # Check if 'access_granted' exists in the session state, if not, initialize it as False\n",
    "    if \"access_granted\" not in st.session_state:\n",
    "        st.session_state.access_granted = False\n",
    "\n",
    "    # Access control: If access has not been granted\n",
    "    if not st.session_state.access_granted:\n",
    "        # Create three columns for layout, with the middle column for the access code input\n",
    "        cols = st.columns([1, 2, 1])\n",
    "        with cols[1]:\n",
    "            # Create a password input field in the middle column for the access code\n",
    "            access_code = st.text_input(\"Enter access code\", type=\"password\")\n",
    "            # Create a submit button in the middle column\n",
    "            if st.button(\"Submit\"):\n",
    "                # Verify the access code\n",
    "                if verify_access_code(access_code):\n",
    "                    # If the access code is correct, set 'access_granted' to True and refresh the page\n",
    "                    st.session_state.access_granted = True\n",
    "                    st.experimental_rerun()  # Refresh the page to reload with granted access\n",
    "                else:\n",
    "                    # If the access code is incorrect, display an error message\n",
    "                    st.error(\"Access denied. Please enter the correct access code.\")\n",
    "            else:\n",
    "                # If the submit button is not clicked, display a message prompting for the access code\n",
    "                st.markdown(\"\"\"\n",
    "                > This dashboard allows you to explore the growth trends of mussels across various locations and periods. \n",
    "                > Please enter the access code to continue.\n",
    "                \"\"\")\n",
    "    else:\n",
    "        # If access is granted, proceed to load necessary files\n",
    "        global loaded_model, df_environment, df_modeling  # Define as global variables\n",
    "\n",
    "        # Load the trained model\n",
    "        loaded_model = load_trained_model('./Data/final_ridge_model.pkl')\n",
    "        # Load the combined data\n",
    "        df_environment = load_data('./Data/combined_data.csv')\n",
    "        \n",
    "        # Load the main data\n",
    "        df_modeling = load_data('./Data/It3 - Mussel + SatML + Weather (Lag Features).csv')\n",
    "\n",
    "        # Drop 'Plot Location' column from the main DataFrame as it is not needed\n",
    "        df_modeling.drop(columns=['Plot Location'], inplace=True)\n",
    "\n",
    "        # Load the main dataset and ensure the 'Year' column is of type int\n",
    "        df = load_data('./Data/Mussel + Satellite + Weather.csv')\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "        # Display the data and visualizations in the app\n",
    "        display_data(df)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd387370",
   "metadata": {},
   "source": [
    "##### *Get Access Code Hashing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1567ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Define the access code\n",
    "access_code = '1'\n",
    "\n",
    "# Hash the access code using SHA-256\n",
    "hashed_access_code = hashlib.sha256(access_code.encode()).hexdigest()\n",
    "\n",
    "# Print the hashed access code\n",
    "print(hashed_access_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1cb959",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5f7c5",
   "metadata": {},
   "source": [
    "#### **Environmental Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to load and process feather files for a specific month\n",
    "def load_and_process_feather(file_path, system, variable_name, month):\n",
    "    # Load data\n",
    "    df = pd.read_feather(file_path)\n",
    "    # Convert date column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    # Filter data for the specified month\n",
    "    df_filtered = df[df['date'].dt.month == month]\n",
    "    # Calculate median values for each location, handling NaN values\n",
    "    df_median = df_filtered.groupby(['y', 'x'])['value'].median().reset_index()\n",
    "    # Rename columns\n",
    "    df_median.columns = ['lat', 'lon', f'{variable_name}_{system}']\n",
    "    df_median['month'] = month\n",
    "    return df_median\n",
    "\n",
    "# Function to load and process precipitation data for a specific month\n",
    "def load_and_process_precipitation(file_path, system, month):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df['YYYYMMDD'], format='%Y%m%d')\n",
    "    df_filtered = df[df['date'].dt.month == month]\n",
    "    # Calculate median precipitation\n",
    "    df_median = df_filtered.groupby('YYYYMMDD')['RD'].median().mean()\n",
    "    # Create a DataFrame with system-wide median precipitation\n",
    "    df_median_df = pd.DataFrame({\n",
    "        'lat': [np.nan],  # Placeholder, as we do not have specific lat/lon\n",
    "        'lon': [np.nan],  # Placeholder, as we do not have specific lat/lon\n",
    "        f'median_precipitation_{system}': [df_median],\n",
    "        'month': [month]\n",
    "    })\n",
    "    return df_median_df\n",
    "\n",
    "# Load and process data for WAD and OS systems for April (lag) and May (current)\n",
    "months = [4, 5]\n",
    "combined_data = []\n",
    "\n",
    "for month in months:\n",
    "    chlorophyll_wad = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_Wadden_Sea_chl_prepped.feather', 'WAD', 'chlorophyll', month)\n",
    "    chlorophyll_os = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_Eastern_Scheldt_chl_prepped.feather', 'OS', 'chlorophyll', month)\n",
    "    sst_wad = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_WAD_sst_prepped.feather', 'WAD', 'sst', month)\n",
    "    sst_os = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_OS_sst_prepped.feather', 'OS', 'sst', month)\n",
    "    turbidity_wad = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_Wadden_Sea_tsm_prepped.feather', 'WAD', 'turbidity', month)\n",
    "    turbidity_os = load_and_process_feather('../Mussels Notebook/Mussels Data/Parsed TIF Data/tifs_Eastern_Scheldt_tsm_prepped.feather', 'OS', 'turbidity', month)\n",
    "    precipitation_wad = load_and_process_precipitation('../Mussels Notebook/Mussels Data/weatherdata-WAD.csv', 'WAD', month)\n",
    "    precipitation_os = load_and_process_precipitation('../Mussels Notebook/Mussels Data/weatherdata-OS.csv', 'OS', month)\n",
    "\n",
    "    combined_data.append(chlorophyll_wad)\n",
    "    combined_data.append(chlorophyll_os)\n",
    "    combined_data.append(sst_wad)\n",
    "    combined_data.append(sst_os)\n",
    "    combined_data.append(turbidity_wad)\n",
    "    combined_data.append(turbidity_os)\n",
    "    combined_data.append(precipitation_wad)\n",
    "    combined_data.append(precipitation_os)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "\n",
    "# Pivot precipitation data to have lat and lon columns\n",
    "combined_df['lat'] = combined_df['lat'].fillna(combined_df['lon'])\n",
    "combined_df['lon'] = combined_df['lon'].fillna(combined_df['lat'])\n",
    "combined_df = combined_df.groupby(['lat', 'lon', 'month']).first().reset_index()\n",
    "\n",
    "# Save the combined dataset to CSV in the specified folder\n",
    "combined_df.to_csv('./Data/combined_data.csv', index=False)\n",
    "\n",
    "print(\"Combined dataset saved to CSV in the './Data/' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e620ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Data/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cbcfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>chlorophyll_WAD</th>\n",
       "      <th>chlorophyll_OS</th>\n",
       "      <th>sst_WAD</th>\n",
       "      <th>sst_OS</th>\n",
       "      <th>turbidity_WAD</th>\n",
       "      <th>turbidity_OS</th>\n",
       "      <th>median_precipitation_WAD</th>\n",
       "      <th>median_precipitation_OS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.409999</td>\n",
       "      <td>3.659997</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.887507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.409999</td>\n",
       "      <td>3.659997</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.236994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.409999</td>\n",
       "      <td>3.669997</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.889994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.409999</td>\n",
       "      <td>3.669997</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.241999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.409999</td>\n",
       "      <td>3.679997</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.891504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat       lon  month  chlorophyll_WAD  chlorophyll_OS  sst_WAD  \\\n",
       "0  51.409999  3.659997      4              NaN             NaN      NaN   \n",
       "1  51.409999  3.659997      5              NaN             NaN      NaN   \n",
       "2  51.409999  3.669997      4              NaN             NaN      NaN   \n",
       "3  51.409999  3.669997      5              NaN             NaN      NaN   \n",
       "4  51.409999  3.679997      4              NaN             NaN      NaN   \n",
       "\n",
       "      sst_OS  turbidity_WAD  turbidity_OS  median_precipitation_WAD  \\\n",
       "0   9.887507            NaN           NaN                       NaN   \n",
       "1  13.236994            NaN           NaN                       NaN   \n",
       "2   9.889994            NaN           NaN                       NaN   \n",
       "3  13.241999            NaN           NaN                       NaN   \n",
       "4   9.891504            NaN           NaN                       NaN   \n",
       "\n",
       "   median_precipitation_OS  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215a43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4689409 entries, 0 to 4689408\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   lat                       float64\n",
      " 1   lon                       float64\n",
      " 2   month                     int64  \n",
      " 3   chlorophyll_WAD           float64\n",
      " 4   chlorophyll_OS            float64\n",
      " 5   sst_WAD                   float64\n",
      " 6   sst_OS                    float64\n",
      " 7   turbidity_WAD             float64\n",
      " 8   turbidity_OS              float64\n",
      " 9   median_precipitation_WAD  float64\n",
      " 10  median_precipitation_OS   float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 393.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5c654b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    2432617\n",
       "5    2256792\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec0371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame size: (4689409, 11)\n",
      "Reduced DataFrame size: (93788, 11)\n"
     ]
    }
   ],
   "source": [
    "# Split the DataFrame for month 4 and month 5\n",
    "df_month_4 = df[df['month'] == 4]\n",
    "df_month_5 = df[df['month'] == 5]\n",
    "\n",
    "# Reduce the DataFrame size by half for each month\n",
    "df_month_4_reduced = df_month_4.sample(frac=0.02, random_state=42)\n",
    "df_month_5_reduced = df_month_5.sample(frac=0.02, random_state=42)\n",
    "\n",
    "# Concatenate the reduced DataFrames back together\n",
    "df_reduced = pd.concat([df_month_4_reduced, df_month_5_reduced], ignore_index=True)\n",
    "\n",
    "print(\"Original DataFrame size:\", df.shape)\n",
    "print(\"Reduced DataFrame size:\", df_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "713b0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.to_csv('./Data/combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74f146",
   "metadata": {},
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d55d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ridge(df, features, target, alpha=1.0, n_splits=5):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    test_mae_sum = 0\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_mae_sum += mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    avg_test_mae = test_mae_sum / n_splits\n",
    "    return avg_test_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, target):\n",
    "    features = [col for col in df.columns if col != target and col not in ['lat', 'lon']]\n",
    "    selected_features = []\n",
    "    mae_results = []\n",
    "\n",
    "    while features:\n",
    "        mae_list = []\n",
    "        for feature in features:\n",
    "            current_features = selected_features + [feature]\n",
    "            avg_test_mae = evaluate_ridge(df, current_features, target)\n",
    "            mae_list.append((feature, avg_test_mae))\n",
    "        \n",
    "        best_feature, best_mae = min(mae_list, key=lambda x: x[1])\n",
    "        selected_features.append(best_feature)\n",
    "        features.remove(best_feature)\n",
    "        mae_results.append((selected_features[:], best_mae))\n",
    "        print(f'Selected Features: {selected_features}, MAE: {best_mae}')\n",
    "\n",
    "    best_combination = min(mae_results, key=lambda x: x[1])\n",
    "    best_features, best_mae = best_combination\n",
    "    print(f'Final selected features: {best_features}')\n",
    "    print(f'Final MAE with the selected features: {best_mae}')\n",
    "\n",
    "    # Plotting the results\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    mae_values = [mae for _, mae in mae_results]\n",
    "    best_combination_idx = mae_values.index(min(mae_values))\n",
    "\n",
    "    ax.plot(range(1, len(mae_values) + 1), mae_values, marker='o', label='MAE')\n",
    "    ax.axvline(x=best_combination_idx + 1, color='green', linestyle='--', label=f'Best combination: {best_combination_idx + 1} features')\n",
    "\n",
    "    plt.xticks(range(1, len(mae_values) + 1))\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Average Test MAE')\n",
    "    plt.title('Feature Selection based on Ridge Regression MAE')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return best_features, best_mae, mae_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for alpha testing\n",
    "def alpha_testing(df, features, target):\n",
    "    scaler = StandardScaler()\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    alphas = np.logspace(-4, 4, num=20)\n",
    "    train_mae = []\n",
    "    test_mae = []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        model = Ridge(alpha=alpha)\n",
    "        test_mae_sum = 0\n",
    "\n",
    "        for train_idx, test_idx in kf.split(df):\n",
    "            X_train, X_test = df.iloc[train_idx][features], df.iloc[test_idx][features]\n",
    "            y_train, y_test = df.iloc[train_idx][target], df.iloc[test_idx][target]\n",
    "\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "            test_mae_sum += mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        avg_test_mae = test_mae_sum / kf.n_splits\n",
    "        test_mae.append(avg_test_mae)\n",
    "\n",
    "        model.fit(scaler.fit_transform(df[features]), df[target])\n",
    "        train_mae.append(mean_absolute_error(df[target], model.predict(scaler.transform(df[features]))))\n",
    "\n",
    "    # Plotting the results\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))  # Adjusted figure size\n",
    "    ax.plot(alphas, train_mae, color='blue', label='Train MAE', marker='o')\n",
    "    ax.plot(alphas, test_mae, color='red', label='Test MAE', marker='o')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Alpha of the Ridge model')\n",
    "    ax.set_ylabel('Mean Absolute Error (MAE)')\n",
    "    ax.set_title('MAE vs. Alpha for Ridge Model')\n",
    "    ax.legend(loc='best')\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Highlight the best alpha\n",
    "    min_mae_alpha = alphas[np.argmin(test_mae)]\n",
    "    ax.axvline(x=min_mae_alpha, color='green', linestyle='--', label=f'Best alpha: {min_mae_alpha:.4f}')\n",
    "    ax.text(min_mae_alpha, min(test_mae) + 0.0005, f'Best alpha: {min_mae_alpha:.4f}',\n",
    "            verticalalignment='bottom', horizontalalignment='right', color='green', fontsize=10)\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.3, top=0.8)  # Adjust margins\n",
    "    plt.show()\n",
    "\n",
    "    return min_mae_alpha, min(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data utama\n",
    "df_main = pd.read_csv('./Data/It3 - Mussel + SatML + Weather (Lag Features).csv')\n",
    "\n",
    "# Menghapus kolom 'Plot Location' yang tidak digunakan\n",
    "df_main.drop(columns=['Plot Location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4553930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleksi fitur\n",
    "target = 'Growth (g per day)'\n",
    "best_features, best_mae, mae_results = feature_selection(df_main, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best feature combination: {best_features}')\n",
    "print(f'Lowest MAE: {best_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha testing with the best features\n",
    "best_alpha, min_mae = alpha_testing(df_main, best_features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7db898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Best alpha: {best_alpha}')\n",
    "print(f'Minimum MAE: {min_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75594591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca data\n",
    "df_main = pd.read_csv('./Data/It3 - Mussel + SatML + Weather (Lag Features).csv')\n",
    "\n",
    "# Fitur dan parameter terbaik berdasarkan hasil sebelumnya\n",
    "best_features = ['Chlorophyll', 'Water Temperature (C)', 'Water Temperature (C)_lag', 'Ash Free Dry Weight (g)_lag',\n",
    "                 'Number of Days', 'Precipitation_lag', 'Turbidity (FTU)', 'Turbidity (FTU)_lag', 'Monitoring Period',\n",
    "                 'Individual Weight (g)_lag', 'Chlorophyll_lag']\n",
    "best_alpha = 1.623776739188721\n",
    "target = 'Growth (g per day)'\n",
    "\n",
    "def evaluate_ridge(df, features, target, alpha, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    model = Ridge(alpha=alpha)\n",
    "    test_mae_sum = 0\n",
    "\n",
    "    for train_idx, test_idx in kf.split(df):\n",
    "        X_train, X_test = df.iloc[train_idx][features], df.iloc[test_idx][features]\n",
    "        y_train, y_test = df.iloc[train_idx][target], df.iloc[test_idx][target]\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        test_mae_sum += mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    avg_test_mae = test_mae_sum / kf.n_splits\n",
    "    return avg_test_mae\n",
    "\n",
    "# Melatih dan mengevaluasi model\n",
    "avg_mae = evaluate_ridge(df_main, best_features, target, best_alpha)\n",
    "print(f'Average Test MAE: {avg_mae}')\n",
    "\n",
    "# Membangun pipeline dengan scaler dan model Ridge\n",
    "final_model_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge(alpha=best_alpha))\n",
    "])\n",
    "\n",
    "# Melatih model dengan data lengkap\n",
    "final_model_pipeline.fit(df_main[best_features], df_main[target])\n",
    "\n",
    "# Menyimpan model ke file\n",
    "model_file = './Data/final_ridge_model.pkl'\n",
    "joblib.dump(final_model_pipeline, model_file)\n",
    "\n",
    "print(f'Model disimpan ke {model_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab440b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model from the file\n",
    "loaded_model = joblib.load('./Data/final_ridge_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feec335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load combined data\n",
    "df_combined = pd.read_csv('./Data/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97cbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Radius of the Earth in kilometers\n",
    "\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5967799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_environmental_data(lat, lon, df, month):\n",
    "    # Filter by month\n",
    "    df_month = df[df['month'] == month].copy()\n",
    "    # Calculate distances to all points in the dataset\n",
    "    df_month['distance'] = df_month.apply(lambda row: haversine(lat, lon, row['lat'], row['lon']), axis=1)\n",
    "    nearest_row = df_month.loc[df_month['distance'].idxmin()]\n",
    "    return nearest_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadfe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_ash_free_dry_weight(period):\n",
    "    # Calculate the average Ash Free Dry Weight (g) for the specified monitoring period\n",
    "    return df_main[df_main['Monitoring Period'] == period]['Ash Free Dry Weight (g)_lag'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_growth(lat, lon, individual_weight, depth, avg_flow_speed, max_flow_speed):\n",
    "    \"\"\"\n",
    "    Predict mussel growth based on user inputs and additional environmental features.\n",
    "\n",
    "    Parameters:\n",
    "    - lat: Latitude of the location.\n",
    "    - lon: Longitude of the location.\n",
    "    - individual_weight: Initial weight of the mussel.\n",
    "    - depth: Depth of the location.\n",
    "    - avg_flow_speed: Average flow speed of the water.\n",
    "    - max_flow_speed: Maximum flow speed of the water.\n",
    "\n",
    "    Returns:\n",
    "    - predictions: DataFrame with columns 'Month' and 'Growth (g per day)'.\n",
    "    \"\"\"\n",
    "    # Get nearest environmental data based on lat and lon for April (lag) and May (current)\n",
    "    env_data_april = get_nearest_environmental_data(lat, lon, df_combined, 4)\n",
    "    env_data_may = get_nearest_environmental_data(lat, lon, df_combined, 5)\n",
    "    \n",
    "    # Create input data frame for prediction\n",
    "    input_data = {\n",
    "        'Chlorophyll': [env_data_may.get('chlorophyll', 0)],\n",
    "        'Water Temperature (C)': [env_data_may.get('sst', 0)],\n",
    "        'Water Temperature (C)_lag': [env_data_april.get('sst', 0)],\n",
    "        'Ash Free Dry Weight (g)_lag': [get_average_ash_free_dry_weight(0)],\n",
    "        'Number of Days': [30],\n",
    "        'Precipitation_lag': [env_data_april.get('precipitation', 0)],\n",
    "        'Turbidity (FTU)': [env_data_may.get('turbidity', 0)],\n",
    "        'Turbidity (FTU)_lag': [env_data_april.get('turbidity', 0)],\n",
    "        'Monitoring Period': [0],\n",
    "        'Individual Weight (g)_lag': [individual_weight],\n",
    "        'Chlorophyll_lag': [env_data_april.get('chlorophyll', 0)]\n",
    "    }\n",
    "\n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    predictions = []\n",
    "\n",
    "    # Perform predictions for each monitoring period\n",
    "    for period in range(1, 7):  # May to October\n",
    "        prediction = loaded_model.predict(input_df[best_features])[0]\n",
    "        predictions.append(prediction)\n",
    "        \n",
    "        # Update input data for the next period\n",
    "        input_df['Monitoring Period'] = period\n",
    "        input_df['Growth (g per day)'] = prediction\n",
    "        input_df['Ash Free Dry Weight (g)_lag'] = get_average_ash_free_dry_weight(period)  # Use average for the next period\n",
    "\n",
    "    # Create DataFrame for predictions with 'Month' and 'Growth (g per day)'\n",
    "    months = ['May', 'June', 'July', 'August', 'September', 'October']\n",
    "    prediction_df = pd.DataFrame({\n",
    "        'Month': months,\n",
    "        'Growth (g per day)': predictions\n",
    "    })\n",
    "\n",
    "    # Plotting the predictions\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(prediction_df['Month'], prediction_df['Growth (g per day)'], marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Growth (g per day)')\n",
    "    plt.title('Predicted Mussel Growth from May to October')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan\n",
    "lat = 52.0\n",
    "lon = 4.0\n",
    "individual_weight = 2.0  # Misal 2 gram\n",
    "depth = 5.0\n",
    "avg_flow_speed = 0.2\n",
    "max_flow_speed = 0.5\n",
    "\n",
    "predictions = predict_growth(lat, lon, individual_weight, depth, avg_flow_speed, max_flow_speed)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alessandroryo",
   "language": "python",
   "name": "alessandroryo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
